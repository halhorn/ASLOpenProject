{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## youtube8Mのデータセット準備\n",
    "\n",
    "とりあえずローカルでDatasetAPIで学習を開始できるようにするのが目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ローカルへのデータダウンロード\n",
    "\n",
    "youtube8mのデータは以下のコマンドで取って来れます。\n",
    "下のセルを実行すると全データの1/100のトレーニングデータを取得します。\n",
    "\n",
    "環境変数からオプションを渡すような作りになってるみたい。\n",
    "このpartition=2の部分がよくわからないけど、とりあえずこのままでw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/ASLOpenProject/youtube8m'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# youtube8m のディレクトリに移動\n",
    "import os\n",
    "while os.getcwd().split('/')[-1] != 'youtube8m': os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET=\"asl-mixi-project-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming Download ...\n",
      "Files remaining 0\n",
      "All done. No more files to download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: PWD: command not found\n",
      "mkdir: cannot create directory ‘./data/video/’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4450  100  4450    0     0  35098      0 --:--:-- --:--:-- --:--:-- 35317\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "CURRENT_DIR=$(PWD)\n",
    "mkdir ./data/video/\n",
    "cd ./data/video/\n",
    "curl data.yt8m.org/download.py > download.py\n",
    "\n",
    "shard=1,100 partition=2/video/train mirror=us python download.py\n",
    "cd $CURRENT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/video/*.tfrecord -l | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 4.6M Dec  6 08:34 ./data/video/train0093.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.7M Dec  6 08:34 ./data/video/train0111.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.6M Dec  6 08:34 ./data/video/train0208.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.7M Dec  6 08:34 ./data/video/train0274.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.4M Dec  6 08:34 ./data/video/train0276.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.5M Dec  6 08:34 ./data/video/train0352.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.5M Dec  6 08:34 ./data/video/train0434.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.5M Dec  6 08:34 ./data/video/train0477.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.5M Dec  6 08:34 ./data/video/train0503.tfrecord\n",
      "-rw-r--r-- 1 jupyter jupyter 4.6M Dec  6 08:34 ./data/video/train0580.tfrecord\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/video/*.tfrecord -alh | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storageへのコピー\n",
    "\n",
    "必要があれば実行。ローカルで実行する分には必要ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "\n",
    "!gsutil cp ./data/video/*.tfrecord gs://$BUCKET/data/youtube-8m/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの作成用のコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_sequence_example is deprecated. Please use tf.io.parse_single_sequence_example instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = read_dataset(\"./data/video/*.tfrecord\", tf.estimator.ModeKeys.TRAIN, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "({'id': <tf.Tensor: id=57, shape=(2,), dtype=string, numpy=array([b'V98D', b'oz8D'], dtype=object)>, 'mean_rgb': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466a84908>, 'mean_audio': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466a84080>}, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466a84278>)\n",
      "mean_rgb: SparseTensor(indices=tf.Tensor(\n",
      "[[   0    0]\n",
      " [   0    1]\n",
      " [   0    2]\n",
      " ...\n",
      " [   1 1021]\n",
      " [   1 1022]\n",
      " [   1 1023]], shape=(2048, 2), dtype=int64), values=tf.Tensor(\n",
      "[-0.8320534   0.8792135   1.6785632  ... -0.01001757 -0.09127247\n",
      " -0.19412214], shape=(2048,), dtype=float32), dense_shape=tf.Tensor([   2 1024], shape=(2,), dtype=int64))\n",
      "mean_audio: SparseTensor(indices=tf.Tensor(\n",
      "[[  0   0]\n",
      " [  0   1]\n",
      " [  0   2]\n",
      " [  0   3]\n",
      " [  0   4]\n",
      " [  0   5]\n",
      " [  0   6]\n",
      " [  0   7]\n",
      " [  0   8]\n",
      " [  0   9]\n",
      " [  0  10]\n",
      " [  0  11]\n",
      " [  0  12]\n",
      " [  0  13]\n",
      " [  0  14]\n",
      " [  0  15]\n",
      " [  0  16]\n",
      " [  0  17]\n",
      " [  0  18]\n",
      " [  0  19]\n",
      " [  0  20]\n",
      " [  0  21]\n",
      " [  0  22]\n",
      " [  0  23]\n",
      " [  0  24]\n",
      " [  0  25]\n",
      " [  0  26]\n",
      " [  0  27]\n",
      " [  0  28]\n",
      " [  0  29]\n",
      " [  0  30]\n",
      " [  0  31]\n",
      " [  0  32]\n",
      " [  0  33]\n",
      " [  0  34]\n",
      " [  0  35]\n",
      " [  0  36]\n",
      " [  0  37]\n",
      " [  0  38]\n",
      " [  0  39]\n",
      " [  0  40]\n",
      " [  0  41]\n",
      " [  0  42]\n",
      " [  0  43]\n",
      " [  0  44]\n",
      " [  0  45]\n",
      " [  0  46]\n",
      " [  0  47]\n",
      " [  0  48]\n",
      " [  0  49]\n",
      " [  0  50]\n",
      " [  0  51]\n",
      " [  0  52]\n",
      " [  0  53]\n",
      " [  0  54]\n",
      " [  0  55]\n",
      " [  0  56]\n",
      " [  0  57]\n",
      " [  0  58]\n",
      " [  0  59]\n",
      " [  0  60]\n",
      " [  0  61]\n",
      " [  0  62]\n",
      " [  0  63]\n",
      " [  0  64]\n",
      " [  0  65]\n",
      " [  0  66]\n",
      " [  0  67]\n",
      " [  0  68]\n",
      " [  0  69]\n",
      " [  0  70]\n",
      " [  0  71]\n",
      " [  0  72]\n",
      " [  0  73]\n",
      " [  0  74]\n",
      " [  0  75]\n",
      " [  0  76]\n",
      " [  0  77]\n",
      " [  0  78]\n",
      " [  0  79]\n",
      " [  0  80]\n",
      " [  0  81]\n",
      " [  0  82]\n",
      " [  0  83]\n",
      " [  0  84]\n",
      " [  0  85]\n",
      " [  0  86]\n",
      " [  0  87]\n",
      " [  0  88]\n",
      " [  0  89]\n",
      " [  0  90]\n",
      " [  0  91]\n",
      " [  0  92]\n",
      " [  0  93]\n",
      " [  0  94]\n",
      " [  0  95]\n",
      " [  0  96]\n",
      " [  0  97]\n",
      " [  0  98]\n",
      " [  0  99]\n",
      " [  0 100]\n",
      " [  0 101]\n",
      " [  0 102]\n",
      " [  0 103]\n",
      " [  0 104]\n",
      " [  0 105]\n",
      " [  0 106]\n",
      " [  0 107]\n",
      " [  0 108]\n",
      " [  0 109]\n",
      " [  0 110]\n",
      " [  0 111]\n",
      " [  0 112]\n",
      " [  0 113]\n",
      " [  0 114]\n",
      " [  0 115]\n",
      " [  0 116]\n",
      " [  0 117]\n",
      " [  0 118]\n",
      " [  0 119]\n",
      " [  0 120]\n",
      " [  0 121]\n",
      " [  0 122]\n",
      " [  0 123]\n",
      " [  0 124]\n",
      " [  0 125]\n",
      " [  0 126]\n",
      " [  0 127]\n",
      " [  1   0]\n",
      " [  1   1]\n",
      " [  1   2]\n",
      " [  1   3]\n",
      " [  1   4]\n",
      " [  1   5]\n",
      " [  1   6]\n",
      " [  1   7]\n",
      " [  1   8]\n",
      " [  1   9]\n",
      " [  1  10]\n",
      " [  1  11]\n",
      " [  1  12]\n",
      " [  1  13]\n",
      " [  1  14]\n",
      " [  1  15]\n",
      " [  1  16]\n",
      " [  1  17]\n",
      " [  1  18]\n",
      " [  1  19]\n",
      " [  1  20]\n",
      " [  1  21]\n",
      " [  1  22]\n",
      " [  1  23]\n",
      " [  1  24]\n",
      " [  1  25]\n",
      " [  1  26]\n",
      " [  1  27]\n",
      " [  1  28]\n",
      " [  1  29]\n",
      " [  1  30]\n",
      " [  1  31]\n",
      " [  1  32]\n",
      " [  1  33]\n",
      " [  1  34]\n",
      " [  1  35]\n",
      " [  1  36]\n",
      " [  1  37]\n",
      " [  1  38]\n",
      " [  1  39]\n",
      " [  1  40]\n",
      " [  1  41]\n",
      " [  1  42]\n",
      " [  1  43]\n",
      " [  1  44]\n",
      " [  1  45]\n",
      " [  1  46]\n",
      " [  1  47]\n",
      " [  1  48]\n",
      " [  1  49]\n",
      " [  1  50]\n",
      " [  1  51]\n",
      " [  1  52]\n",
      " [  1  53]\n",
      " [  1  54]\n",
      " [  1  55]\n",
      " [  1  56]\n",
      " [  1  57]\n",
      " [  1  58]\n",
      " [  1  59]\n",
      " [  1  60]\n",
      " [  1  61]\n",
      " [  1  62]\n",
      " [  1  63]\n",
      " [  1  64]\n",
      " [  1  65]\n",
      " [  1  66]\n",
      " [  1  67]\n",
      " [  1  68]\n",
      " [  1  69]\n",
      " [  1  70]\n",
      " [  1  71]\n",
      " [  1  72]\n",
      " [  1  73]\n",
      " [  1  74]\n",
      " [  1  75]\n",
      " [  1  76]\n",
      " [  1  77]\n",
      " [  1  78]\n",
      " [  1  79]\n",
      " [  1  80]\n",
      " [  1  81]\n",
      " [  1  82]\n",
      " [  1  83]\n",
      " [  1  84]\n",
      " [  1  85]\n",
      " [  1  86]\n",
      " [  1  87]\n",
      " [  1  88]\n",
      " [  1  89]\n",
      " [  1  90]\n",
      " [  1  91]\n",
      " [  1  92]\n",
      " [  1  93]\n",
      " [  1  94]\n",
      " [  1  95]\n",
      " [  1  96]\n",
      " [  1  97]\n",
      " [  1  98]\n",
      " [  1  99]\n",
      " [  1 100]\n",
      " [  1 101]\n",
      " [  1 102]\n",
      " [  1 103]\n",
      " [  1 104]\n",
      " [  1 105]\n",
      " [  1 106]\n",
      " [  1 107]\n",
      " [  1 108]\n",
      " [  1 109]\n",
      " [  1 110]\n",
      " [  1 111]\n",
      " [  1 112]\n",
      " [  1 113]\n",
      " [  1 114]\n",
      " [  1 115]\n",
      " [  1 116]\n",
      " [  1 117]\n",
      " [  1 118]\n",
      " [  1 119]\n",
      " [  1 120]\n",
      " [  1 121]\n",
      " [  1 122]\n",
      " [  1 123]\n",
      " [  1 124]\n",
      " [  1 125]\n",
      " [  1 126]\n",
      " [  1 127]], shape=(256, 2), dtype=int64), values=tf.Tensor(\n",
      "[ 1.04932427e+00  1.75187433e+00  1.84534168e+00  1.55856788e-01\n",
      " -3.70080411e-01 -1.17230676e-01 -4.87849385e-01  2.94513702e-01\n",
      " -1.28923106e+00 -6.41461074e-01  2.38758355e-01  8.27847064e-01\n",
      "  4.73320991e-01  1.13726485e+00 -3.21070969e-01  3.84242445e-01\n",
      "  1.11317530e-01  5.99136293e-01 -1.32320452e+00  3.46205264e-01\n",
      "  3.61810267e-01 -9.64939713e-01 -6.15534067e-01  5.83531260e-01\n",
      " -6.22198701e-01 -7.26914108e-02 -4.13969487e-01 -2.80514240e-01\n",
      " -6.40761554e-02  9.70161378e-01  1.70242652e-01 -2.55074829e-01\n",
      " -3.14031877e-02  1.34481192e-01  1.12938118e+00 -3.62115353e-01\n",
      " -1.72904760e-01  7.57949650e-01  6.52209520e-01  9.98851836e-01\n",
      " -6.89007580e-01  1.15868986e-01  8.32317233e-01  1.23752765e-01\n",
      " -1.36327350e+00  8.27847064e-01 -5.01910150e-01 -1.51891720e+00\n",
      "  7.34867275e-01 -4.66717631e-01  1.13376999e+00 -6.74459159e-01\n",
      "  6.86995685e-01  3.71937864e-02  7.72823155e-01 -2.85472065e-01\n",
      "  6.58223987e-01 -1.08449674e+00 -8.26120257e-01  1.12344801e+00\n",
      " -1.19738913e+00  2.14294270e-01  6.32459462e-01  5.67032278e-01\n",
      " -7.19242275e-01 -5.58803380e-01 -8.49202633e-01 -4.19740081e-01\n",
      "  3.02153647e-01  3.32469612e-01  6.36685789e-01  2.24453762e-01\n",
      " -9.77244303e-02  9.53337252e-01 -1.22494173e+00 -7.99217880e-01\n",
      " -1.04857278e+00 -4.97114867e-01  9.78370249e-01 -1.09408736e+00\n",
      " -1.05889475e+00 -3.47973347e-01  2.47779995e-01 -5.67499876e-01\n",
      "  2.38189414e-01 -2.23539725e-01 -9.95743334e-01  8.16305816e-01\n",
      " -5.37102640e-01  2.91343957e-01 -8.78543258e-01  9.56181884e-01\n",
      "  1.15457666e+00  1.67615945e-03  4.94777858e-01 -2.80026585e-01\n",
      " -7.34847248e-01 -1.63558021e-01  3.52869898e-01 -8.32866132e-01\n",
      "  7.14629531e-01 -1.34461194e-01 -4.16326493e-01  9.37732220e-01\n",
      " -4.58703190e-02  1.12645519e+00 -5.95783949e-01 -6.07812822e-01\n",
      "  1.31961644e-01 -6.95184529e-01 -2.75312573e-01  8.15980732e-01\n",
      "  6.41562402e-01  4.26831096e-01  5.08188426e-01 -3.03434074e-01\n",
      " -3.42040181e-01 -7.68007874e-01  8.25490057e-01 -5.54170609e-01\n",
      "  2.94757545e-01 -9.72986042e-01 -5.54576993e-01 -1.34644938e+00\n",
      " -8.65083337e-02 -1.15114307e+00  1.29095793e+00  1.99908406e-01\n",
      " -7.51612365e-01 -5.24318218e-01  6.36033490e-02  8.39498758e-01\n",
      "  1.20755100e+00  4.66098860e-02  7.27237344e-01 -3.43664616e-01\n",
      " -4.31664616e-01  6.21407270e-01  4.78505313e-01  3.22949767e-01\n",
      " -1.32593950e-02  1.81145832e-01 -5.10828018e-01 -3.27769190e-01\n",
      "  5.07002056e-01 -3.23324770e-01 -1.57834560e-01  3.84073943e-01\n",
      " -1.68867245e-01  5.80832124e-01 -6.67533934e-01 -1.92201789e-02\n",
      "  1.32373405e+00 -4.33442414e-01  3.45956296e-01 -4.97599274e-01\n",
      " -1.98999178e-02  9.68059674e-02  2.62766749e-01  2.16492236e-01\n",
      " -1.26984879e-01  3.66191596e-01 -5.11769176e-01  3.30674015e-02\n",
      " -1.29456697e-02  2.65067399e-01  2.70714462e-01  7.01407254e-01\n",
      "  1.03080474e-01  6.13549836e-02 -4.09285545e-01 -9.17520821e-01\n",
      " -4.90854174e-01 -1.09142935e+00 -2.30043709e-01  1.60596818e-01\n",
      " -5.63899934e-01  1.11185052e-01 -1.35612339e-01  3.45171988e-01\n",
      " -1.08527370e-01 -5.63586175e-01 -4.46514308e-01 -8.34749579e-01\n",
      " -5.73677719e-01 -7.70958722e-01  5.85224271e-01  4.04675245e-01\n",
      "  2.10426882e-01 -9.05337811e-01  2.53811274e-02  8.51629496e-01\n",
      "  9.43707943e-01 -2.49965280e-01 -6.24097213e-02 -3.48541662e-02\n",
      "  1.10077977e+00  4.14557606e-01  7.47420371e-01  4.65642571e-01\n",
      " -7.15600476e-02 -3.88945669e-01 -2.15350896e-01 -5.91678917e-02\n",
      "  5.12335360e-01 -5.11678904e-02  4.64701384e-01  2.97276556e-01\n",
      " -2.02854171e-01  8.33590269e-01 -3.78069848e-01  5.39824329e-02\n",
      " -2.08410956e-02  4.81956303e-01 -4.45468545e-01  4.23185050e-01\n",
      "  2.71289617e-01 -7.87757337e-02 -2.65337825e-01  1.95838645e-01\n",
      "  1.81354985e-01  3.34191591e-01  5.41616440e-01  1.48152366e-01\n",
      "  4.33747143e-01 -6.22409701e-01 -1.89259395e-01  3.63106608e-01\n",
      " -4.39560056e-01 -2.29363978e-01 -6.11743033e-01 -2.77953427e-02\n",
      "  6.31864786e-01  2.64649093e-01 -2.65024096e-01 -7.70226717e-01\n",
      " -3.08631957e-01  1.03812501e-01 -3.77299823e-02  7.31196925e-02\n",
      "  6.01851702e-01 -2.68945664e-01 -4.80239779e-01  9.27798226e-02\n",
      " -9.50723469e-01 -1.86592728e-01  3.02505314e-01  6.63864791e-01\n",
      "  1.83223039e-02  3.59603345e-01  1.77171975e-01 -7.14331269e-01\n",
      "  6.18255734e-02 -4.15873766e-01 -8.34816173e-02  2.35315770e-01], shape=(256,), dtype=float32), dense_shape=tf.Tensor([  2 128], shape=(2,), dtype=int64))\n",
      "-----\n",
      "({'id': <tf.Tensor: id=70, shape=(2,), dtype=string, numpy=array([b'168D', b'aE8D'], dtype=object)>, 'mean_rgb': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466a8b278>, 'mean_audio': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466a8b160>}, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466a8bc88>)\n",
      "mean_rgb: SparseTensor(indices=tf.Tensor(\n",
      "[[   0    0]\n",
      " [   0    1]\n",
      " [   0    2]\n",
      " ...\n",
      " [   1 1021]\n",
      " [   1 1022]\n",
      " [   1 1023]], shape=(2048, 2), dtype=int64), values=tf.Tensor(\n",
      "[ 0.24126838 -0.22392769 -0.40628064 ... -0.3176777   0.02898897\n",
      "  0.36279288], shape=(2048,), dtype=float32), dense_shape=tf.Tensor([   2 1024], shape=(2,), dtype=int64))\n",
      "mean_audio: SparseTensor(indices=tf.Tensor(\n",
      "[[  0   0]\n",
      " [  0   1]\n",
      " [  0   2]\n",
      " [  0   3]\n",
      " [  0   4]\n",
      " [  0   5]\n",
      " [  0   6]\n",
      " [  0   7]\n",
      " [  0   8]\n",
      " [  0   9]\n",
      " [  0  10]\n",
      " [  0  11]\n",
      " [  0  12]\n",
      " [  0  13]\n",
      " [  0  14]\n",
      " [  0  15]\n",
      " [  0  16]\n",
      " [  0  17]\n",
      " [  0  18]\n",
      " [  0  19]\n",
      " [  0  20]\n",
      " [  0  21]\n",
      " [  0  22]\n",
      " [  0  23]\n",
      " [  0  24]\n",
      " [  0  25]\n",
      " [  0  26]\n",
      " [  0  27]\n",
      " [  0  28]\n",
      " [  0  29]\n",
      " [  0  30]\n",
      " [  0  31]\n",
      " [  0  32]\n",
      " [  0  33]\n",
      " [  0  34]\n",
      " [  0  35]\n",
      " [  0  36]\n",
      " [  0  37]\n",
      " [  0  38]\n",
      " [  0  39]\n",
      " [  0  40]\n",
      " [  0  41]\n",
      " [  0  42]\n",
      " [  0  43]\n",
      " [  0  44]\n",
      " [  0  45]\n",
      " [  0  46]\n",
      " [  0  47]\n",
      " [  0  48]\n",
      " [  0  49]\n",
      " [  0  50]\n",
      " [  0  51]\n",
      " [  0  52]\n",
      " [  0  53]\n",
      " [  0  54]\n",
      " [  0  55]\n",
      " [  0  56]\n",
      " [  0  57]\n",
      " [  0  58]\n",
      " [  0  59]\n",
      " [  0  60]\n",
      " [  0  61]\n",
      " [  0  62]\n",
      " [  0  63]\n",
      " [  0  64]\n",
      " [  0  65]\n",
      " [  0  66]\n",
      " [  0  67]\n",
      " [  0  68]\n",
      " [  0  69]\n",
      " [  0  70]\n",
      " [  0  71]\n",
      " [  0  72]\n",
      " [  0  73]\n",
      " [  0  74]\n",
      " [  0  75]\n",
      " [  0  76]\n",
      " [  0  77]\n",
      " [  0  78]\n",
      " [  0  79]\n",
      " [  0  80]\n",
      " [  0  81]\n",
      " [  0  82]\n",
      " [  0  83]\n",
      " [  0  84]\n",
      " [  0  85]\n",
      " [  0  86]\n",
      " [  0  87]\n",
      " [  0  88]\n",
      " [  0  89]\n",
      " [  0  90]\n",
      " [  0  91]\n",
      " [  0  92]\n",
      " [  0  93]\n",
      " [  0  94]\n",
      " [  0  95]\n",
      " [  0  96]\n",
      " [  0  97]\n",
      " [  0  98]\n",
      " [  0  99]\n",
      " [  0 100]\n",
      " [  0 101]\n",
      " [  0 102]\n",
      " [  0 103]\n",
      " [  0 104]\n",
      " [  0 105]\n",
      " [  0 106]\n",
      " [  0 107]\n",
      " [  0 108]\n",
      " [  0 109]\n",
      " [  0 110]\n",
      " [  0 111]\n",
      " [  0 112]\n",
      " [  0 113]\n",
      " [  0 114]\n",
      " [  0 115]\n",
      " [  0 116]\n",
      " [  0 117]\n",
      " [  0 118]\n",
      " [  0 119]\n",
      " [  0 120]\n",
      " [  0 121]\n",
      " [  0 122]\n",
      " [  0 123]\n",
      " [  0 124]\n",
      " [  0 125]\n",
      " [  0 126]\n",
      " [  0 127]\n",
      " [  1   0]\n",
      " [  1   1]\n",
      " [  1   2]\n",
      " [  1   3]\n",
      " [  1   4]\n",
      " [  1   5]\n",
      " [  1   6]\n",
      " [  1   7]\n",
      " [  1   8]\n",
      " [  1   9]\n",
      " [  1  10]\n",
      " [  1  11]\n",
      " [  1  12]\n",
      " [  1  13]\n",
      " [  1  14]\n",
      " [  1  15]\n",
      " [  1  16]\n",
      " [  1  17]\n",
      " [  1  18]\n",
      " [  1  19]\n",
      " [  1  20]\n",
      " [  1  21]\n",
      " [  1  22]\n",
      " [  1  23]\n",
      " [  1  24]\n",
      " [  1  25]\n",
      " [  1  26]\n",
      " [  1  27]\n",
      " [  1  28]\n",
      " [  1  29]\n",
      " [  1  30]\n",
      " [  1  31]\n",
      " [  1  32]\n",
      " [  1  33]\n",
      " [  1  34]\n",
      " [  1  35]\n",
      " [  1  36]\n",
      " [  1  37]\n",
      " [  1  38]\n",
      " [  1  39]\n",
      " [  1  40]\n",
      " [  1  41]\n",
      " [  1  42]\n",
      " [  1  43]\n",
      " [  1  44]\n",
      " [  1  45]\n",
      " [  1  46]\n",
      " [  1  47]\n",
      " [  1  48]\n",
      " [  1  49]\n",
      " [  1  50]\n",
      " [  1  51]\n",
      " [  1  52]\n",
      " [  1  53]\n",
      " [  1  54]\n",
      " [  1  55]\n",
      " [  1  56]\n",
      " [  1  57]\n",
      " [  1  58]\n",
      " [  1  59]\n",
      " [  1  60]\n",
      " [  1  61]\n",
      " [  1  62]\n",
      " [  1  63]\n",
      " [  1  64]\n",
      " [  1  65]\n",
      " [  1  66]\n",
      " [  1  67]\n",
      " [  1  68]\n",
      " [  1  69]\n",
      " [  1  70]\n",
      " [  1  71]\n",
      " [  1  72]\n",
      " [  1  73]\n",
      " [  1  74]\n",
      " [  1  75]\n",
      " [  1  76]\n",
      " [  1  77]\n",
      " [  1  78]\n",
      " [  1  79]\n",
      " [  1  80]\n",
      " [  1  81]\n",
      " [  1  82]\n",
      " [  1  83]\n",
      " [  1  84]\n",
      " [  1  85]\n",
      " [  1  86]\n",
      " [  1  87]\n",
      " [  1  88]\n",
      " [  1  89]\n",
      " [  1  90]\n",
      " [  1  91]\n",
      " [  1  92]\n",
      " [  1  93]\n",
      " [  1  94]\n",
      " [  1  95]\n",
      " [  1  96]\n",
      " [  1  97]\n",
      " [  1  98]\n",
      " [  1  99]\n",
      " [  1 100]\n",
      " [  1 101]\n",
      " [  1 102]\n",
      " [  1 103]\n",
      " [  1 104]\n",
      " [  1 105]\n",
      " [  1 106]\n",
      " [  1 107]\n",
      " [  1 108]\n",
      " [  1 109]\n",
      " [  1 110]\n",
      " [  1 111]\n",
      " [  1 112]\n",
      " [  1 113]\n",
      " [  1 114]\n",
      " [  1 115]\n",
      " [  1 116]\n",
      " [  1 117]\n",
      " [  1 118]\n",
      " [  1 119]\n",
      " [  1 120]\n",
      " [  1 121]\n",
      " [  1 122]\n",
      " [  1 123]\n",
      " [  1 124]\n",
      " [  1 125]\n",
      " [  1 126]\n",
      " [  1 127]], shape=(256, 2), dtype=int64), values=tf.Tensor(\n",
      "[ 8.66636038e-01 -3.78339469e-01 -8.73437524e-01  2.18841910e-01\n",
      "  5.26685059e-01 -4.91942406e-01 -4.15839463e-01  3.51409316e-02\n",
      " -4.85814959e-01  7.30085820e-02 -1.69708943e+00 -2.81035542e-01\n",
      "  2.00827211e-01 -2.75888473e-01  1.02787994e-01 -8.88480397e-04\n",
      "  4.47886020e-01 -5.57015955e-01  7.99601734e-01 -3.63020837e-01\n",
      " -3.12806368e-02 -2.28462011e-01  4.47028190e-01  1.01562500e-01\n",
      " -4.70618874e-01  2.31311265e-02 -3.12775731e-01 -2.56893396e-01\n",
      " -8.61795366e-01  1.82291660e-02 -3.79564941e-01  4.38419133e-02\n",
      "  5.34038007e-01  7.64920354e-01 -1.91207111e-01  3.37959558e-01\n",
      " -4.20618862e-01 -1.12162992e-01 -3.73927683e-01 -1.54197305e-01\n",
      " -1.53462008e-01 -4.53339458e-01 -3.24785531e-01 -3.53339463e-01\n",
      " -1.12530634e-01  3.25827211e-01  3.61366421e-01  2.54258573e-01\n",
      " -6.31280661e-01  4.25337017e-01 -4.92555141e-01  6.62346840e-01\n",
      "  4.43596810e-01 -7.79564977e-01 -3.34466904e-01 -3.24785531e-01\n",
      " -1.66697308e-01 -2.41819859e-01 -2.60324746e-01 -1.07261032e-01\n",
      "  5.42984068e-01 -1.25612749e-03  2.54136026e-01 -7.19669089e-02\n",
      "  1.61611512e-01 -1.06525734e-01 -4.41697299e-01 -6.00030661e-01\n",
      "  2.87959546e-01  7.17830881e-02  4.08547789e-01  3.50949764e-01\n",
      " -6.32659346e-02  2.40778193e-01 -6.12163007e-01  2.02910542e-01\n",
      " -2.00520828e-01  3.85140926e-01  7.54258573e-01 -1.72579661e-01\n",
      " -1.61795348e-01  3.84405643e-01 -1.63296573e-02  2.31219366e-01\n",
      " -4.81004920e-03 -9.40257385e-02  6.20435059e-01 -5.33854187e-01\n",
      "  1.35263488e-01  5.79993844e-01 -5.10324776e-01 -5.49050272e-01\n",
      " -1.00030638e-01 -2.50030637e-01 -8.72702181e-01  5.57291657e-02\n",
      " -2.21476719e-01  1.59773290e-01  4.58792895e-01  1.79503679e-01\n",
      "  1.26317397e-01  3.18474263e-01 -3.15257348e-02 -1.20251223e-01\n",
      "  4.31709558e-01  2.50091910e-01 -2.38633573e-01  2.62837023e-01\n",
      "  1.22150734e-01  2.20925242e-01 -8.60906858e-03 -1.68412983e-01\n",
      " -3.95496309e-01 -1.74662992e-01 -1.54319853e-01  3.31709564e-01\n",
      " -4.53584552e-01 -3.38633567e-01 -3.01133573e-01  1.56954661e-01\n",
      " -3.05545330e-01  4.58180159e-01 -3.20618868e-01  3.03308829e-03\n",
      " -4.41452205e-01  9.78860259e-02 -2.06158087e-01 -7.92555153e-01\n",
      " -8.49337816e-01 -1.03203058e+00  6.27734065e-01 -3.38749588e-01\n",
      " -4.26540434e-01  2.03995511e-01 -1.02847505e+00 -4.82383579e-01\n",
      "  9.55158889e-01 -1.10732472e+00 -8.15664649e-01 -7.00056791e-01\n",
      "  9.61799443e-01  1.07542038e+00 -1.06774306e+00 -1.06120706e+00\n",
      " -5.11821508e-01 -1.07067120e+00  8.33381116e-01  7.91760206e-01\n",
      "  5.18662155e-01 -2.71298617e-01  7.43394196e-01 -4.52161342e-01\n",
      "  6.84152365e-01 -1.66580882e-02  1.77642569e-01 -1.03835738e+00\n",
      "  4.64753687e-01  8.84204686e-01  3.12126219e-01  9.03551042e-01\n",
      "  2.13250414e-01  4.86243874e-01  1.73145831e-01 -3.49782258e-01\n",
      "  4.44936693e-01  7.41654411e-02 -7.86958754e-01 -3.46122146e-01\n",
      " -1.24677575e+00  1.34191588e-01  4.89105396e-02 -5.84448934e-01\n",
      "  3.33041251e-01  6.09903991e-01 -2.66017556e-01 -4.13625419e-01\n",
      " -2.68841088e-01 -2.14618877e-01  5.24727523e-01  3.90453011e-01\n",
      "  1.10360336e+00 -5.43194056e-01 -4.05154824e-01  8.45354974e-01\n",
      "  1.26871318e-01  1.38479173e-01  1.28211319e+00  1.76021650e-01\n",
      " -1.01430511e+00  5.67917049e-01  9.18819010e-01  3.28701377e-01\n",
      "  9.08413827e-01  6.24753654e-01  2.79864788e-01  4.51943219e-01\n",
      "  8.89747143e-01  5.96518397e-01  6.66322291e-01 -4.47246313e-01\n",
      "  2.45968141e-02 -3.35612327e-01  2.40492240e-01  7.98557580e-01\n",
      " -6.77363992e-01  2.53198117e-01  5.95368028e-01 -3.91350895e-01\n",
      "  3.09407264e-01  1.13956288e-01  7.56817833e-02  2.34531447e-01\n",
      "  5.28283060e-01 -5.46226740e-01 -5.92867255e-01  1.01084518e+00\n",
      " -5.24684250e-01 -1.01482797e+00  4.14557606e-01 -3.23795348e-01\n",
      " -7.18880296e-01  2.69616425e-01 -4.72971827e-01  1.16148567e+00\n",
      " -7.97834992e-03  5.37119687e-01 -1.01834558e-01 -4.10069853e-01\n",
      "  1.43132761e-01 -5.45024097e-01 -1.03141747e-01 -8.32292080e-01\n",
      "  6.29616017e-03 -5.66671133e-01  8.79969358e-01 -1.46906450e-01\n",
      "  5.31577229e-01  3.37119699e-01  4.78243887e-01  5.81721008e-01\n",
      "  7.45314509e-02  2.33224258e-01 -3.83664638e-01  4.00805950e-01\n",
      "  5.25183827e-02  1.25302702e-01 -4.72867250e-01  2.67263472e-01\n",
      " -1.26910257e+00 -2.80448943e-01 -1.25834554e-01 -5.73102534e-01\n",
      " -8.97561312e-02 -2.31037170e-01  7.92544544e-01  1.30897462e-01], shape=(256,), dtype=float32), dense_shape=tf.Tensor([  2 128], shape=(2,), dtype=int64))\n",
      "-----\n",
      "({'id': <tf.Tensor: id=83, shape=(2,), dtype=string, numpy=array([b'pF8D', b'zf8D'], dtype=object)>, 'mean_rgb': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466aaa6a0>, 'mean_audio': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466aaa0f0>}, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa466aaa978>)\n",
      "mean_rgb: SparseTensor(indices=tf.Tensor(\n",
      "[[   0    0]\n",
      " [   0    1]\n",
      " [   0    2]\n",
      " ...\n",
      " [   1 1021]\n",
      " [   1 1022]\n",
      " [   1 1023]], shape=(2048, 2), dtype=int64), values=tf.Tensor(\n",
      "[ 0.71845305  0.91160333  0.33596936 ...  0.49195424  0.8351947\n",
      " -0.75909495], shape=(2048,), dtype=float32), dense_shape=tf.Tensor([   2 1024], shape=(2,), dtype=int64))\n",
      "mean_audio: SparseTensor(indices=tf.Tensor(\n",
      "[[  0   0]\n",
      " [  0   1]\n",
      " [  0   2]\n",
      " [  0   3]\n",
      " [  0   4]\n",
      " [  0   5]\n",
      " [  0   6]\n",
      " [  0   7]\n",
      " [  0   8]\n",
      " [  0   9]\n",
      " [  0  10]\n",
      " [  0  11]\n",
      " [  0  12]\n",
      " [  0  13]\n",
      " [  0  14]\n",
      " [  0  15]\n",
      " [  0  16]\n",
      " [  0  17]\n",
      " [  0  18]\n",
      " [  0  19]\n",
      " [  0  20]\n",
      " [  0  21]\n",
      " [  0  22]\n",
      " [  0  23]\n",
      " [  0  24]\n",
      " [  0  25]\n",
      " [  0  26]\n",
      " [  0  27]\n",
      " [  0  28]\n",
      " [  0  29]\n",
      " [  0  30]\n",
      " [  0  31]\n",
      " [  0  32]\n",
      " [  0  33]\n",
      " [  0  34]\n",
      " [  0  35]\n",
      " [  0  36]\n",
      " [  0  37]\n",
      " [  0  38]\n",
      " [  0  39]\n",
      " [  0  40]\n",
      " [  0  41]\n",
      " [  0  42]\n",
      " [  0  43]\n",
      " [  0  44]\n",
      " [  0  45]\n",
      " [  0  46]\n",
      " [  0  47]\n",
      " [  0  48]\n",
      " [  0  49]\n",
      " [  0  50]\n",
      " [  0  51]\n",
      " [  0  52]\n",
      " [  0  53]\n",
      " [  0  54]\n",
      " [  0  55]\n",
      " [  0  56]\n",
      " [  0  57]\n",
      " [  0  58]\n",
      " [  0  59]\n",
      " [  0  60]\n",
      " [  0  61]\n",
      " [  0  62]\n",
      " [  0  63]\n",
      " [  0  64]\n",
      " [  0  65]\n",
      " [  0  66]\n",
      " [  0  67]\n",
      " [  0  68]\n",
      " [  0  69]\n",
      " [  0  70]\n",
      " [  0  71]\n",
      " [  0  72]\n",
      " [  0  73]\n",
      " [  0  74]\n",
      " [  0  75]\n",
      " [  0  76]\n",
      " [  0  77]\n",
      " [  0  78]\n",
      " [  0  79]\n",
      " [  0  80]\n",
      " [  0  81]\n",
      " [  0  82]\n",
      " [  0  83]\n",
      " [  0  84]\n",
      " [  0  85]\n",
      " [  0  86]\n",
      " [  0  87]\n",
      " [  0  88]\n",
      " [  0  89]\n",
      " [  0  90]\n",
      " [  0  91]\n",
      " [  0  92]\n",
      " [  0  93]\n",
      " [  0  94]\n",
      " [  0  95]\n",
      " [  0  96]\n",
      " [  0  97]\n",
      " [  0  98]\n",
      " [  0  99]\n",
      " [  0 100]\n",
      " [  0 101]\n",
      " [  0 102]\n",
      " [  0 103]\n",
      " [  0 104]\n",
      " [  0 105]\n",
      " [  0 106]\n",
      " [  0 107]\n",
      " [  0 108]\n",
      " [  0 109]\n",
      " [  0 110]\n",
      " [  0 111]\n",
      " [  0 112]\n",
      " [  0 113]\n",
      " [  0 114]\n",
      " [  0 115]\n",
      " [  0 116]\n",
      " [  0 117]\n",
      " [  0 118]\n",
      " [  0 119]\n",
      " [  0 120]\n",
      " [  0 121]\n",
      " [  0 122]\n",
      " [  0 123]\n",
      " [  0 124]\n",
      " [  0 125]\n",
      " [  0 126]\n",
      " [  0 127]\n",
      " [  1   0]\n",
      " [  1   1]\n",
      " [  1   2]\n",
      " [  1   3]\n",
      " [  1   4]\n",
      " [  1   5]\n",
      " [  1   6]\n",
      " [  1   7]\n",
      " [  1   8]\n",
      " [  1   9]\n",
      " [  1  10]\n",
      " [  1  11]\n",
      " [  1  12]\n",
      " [  1  13]\n",
      " [  1  14]\n",
      " [  1  15]\n",
      " [  1  16]\n",
      " [  1  17]\n",
      " [  1  18]\n",
      " [  1  19]\n",
      " [  1  20]\n",
      " [  1  21]\n",
      " [  1  22]\n",
      " [  1  23]\n",
      " [  1  24]\n",
      " [  1  25]\n",
      " [  1  26]\n",
      " [  1  27]\n",
      " [  1  28]\n",
      " [  1  29]\n",
      " [  1  30]\n",
      " [  1  31]\n",
      " [  1  32]\n",
      " [  1  33]\n",
      " [  1  34]\n",
      " [  1  35]\n",
      " [  1  36]\n",
      " [  1  37]\n",
      " [  1  38]\n",
      " [  1  39]\n",
      " [  1  40]\n",
      " [  1  41]\n",
      " [  1  42]\n",
      " [  1  43]\n",
      " [  1  44]\n",
      " [  1  45]\n",
      " [  1  46]\n",
      " [  1  47]\n",
      " [  1  48]\n",
      " [  1  49]\n",
      " [  1  50]\n",
      " [  1  51]\n",
      " [  1  52]\n",
      " [  1  53]\n",
      " [  1  54]\n",
      " [  1  55]\n",
      " [  1  56]\n",
      " [  1  57]\n",
      " [  1  58]\n",
      " [  1  59]\n",
      " [  1  60]\n",
      " [  1  61]\n",
      " [  1  62]\n",
      " [  1  63]\n",
      " [  1  64]\n",
      " [  1  65]\n",
      " [  1  66]\n",
      " [  1  67]\n",
      " [  1  68]\n",
      " [  1  69]\n",
      " [  1  70]\n",
      " [  1  71]\n",
      " [  1  72]\n",
      " [  1  73]\n",
      " [  1  74]\n",
      " [  1  75]\n",
      " [  1  76]\n",
      " [  1  77]\n",
      " [  1  78]\n",
      " [  1  79]\n",
      " [  1  80]\n",
      " [  1  81]\n",
      " [  1  82]\n",
      " [  1  83]\n",
      " [  1  84]\n",
      " [  1  85]\n",
      " [  1  86]\n",
      " [  1  87]\n",
      " [  1  88]\n",
      " [  1  89]\n",
      " [  1  90]\n",
      " [  1  91]\n",
      " [  1  92]\n",
      " [  1  93]\n",
      " [  1  94]\n",
      " [  1  95]\n",
      " [  1  96]\n",
      " [  1  97]\n",
      " [  1  98]\n",
      " [  1  99]\n",
      " [  1 100]\n",
      " [  1 101]\n",
      " [  1 102]\n",
      " [  1 103]\n",
      " [  1 104]\n",
      " [  1 105]\n",
      " [  1 106]\n",
      " [  1 107]\n",
      " [  1 108]\n",
      " [  1 109]\n",
      " [  1 110]\n",
      " [  1 111]\n",
      " [  1 112]\n",
      " [  1 113]\n",
      " [  1 114]\n",
      " [  1 115]\n",
      " [  1 116]\n",
      " [  1 117]\n",
      " [  1 118]\n",
      " [  1 119]\n",
      " [  1 120]\n",
      " [  1 121]\n",
      " [  1 122]\n",
      " [  1 123]\n",
      " [  1 124]\n",
      " [  1 125]\n",
      " [  1 126]\n",
      " [  1 127]], shape=(256, 2), dtype=int64), values=tf.Tensor(\n",
      "[ 1.020989    1.0676818   0.68718505 -0.24217443 -0.8429065   1.0650674\n",
      " -0.01310253 -0.49545547  1.6187406   1.907525    0.764623   -0.4140437\n",
      " -0.4768934  -0.30439666 -0.61514175  0.3345576   0.91730267 -0.40118095\n",
      "  1.3800478  -0.3888411   0.9358648   1.4438909   0.29680598 -0.67888033\n",
      " -0.29859272  0.82517195  0.56096286 -1.7191417   0.7565707  -1.3633248\n",
      "  1.5797341  -0.32635742 -0.36452737  0.05675368 -1.6878215  -0.43647507\n",
      "  1.219891   -0.97759926 -0.55715483 -0.9154816  -0.5024097   0.72462296\n",
      "  0.71045303  0.8605184  -0.6399261   0.413721    1.5626884  -0.04379534\n",
      "  1.0589497  -0.07234436 -0.17346855  0.2128844  -1.5977823   1.1267145\n",
      "  0.21999551  0.7883092   0.90349877  0.15160336  0.27238765 -1.384815\n",
      " -0.08405678 -1.5207103   1.175551   -0.92541623  0.26271448 -0.42110252\n",
      " -0.806096    0.01999551 -0.3235339  -0.8407627  -0.84353393  0.8237602\n",
      "  0.42271447  1.0722308   1.4686229  -0.827377    1.3003615   0.44274062\n",
      "  0.10820466  0.34579942 -0.1770241  -1.2153509   1.6110543   0.9045968\n",
      " -0.33064502 -1.6174424   1.471917    0.9727798  -0.9404751   0.00498897\n",
      " -0.5651548   1.1161524   1.5034465  -1.3590372   1.1030282  -0.7688149\n",
      " -0.75020057 -1.2211025  -0.84123325  0.5502962  -0.7791156  -0.879194\n",
      "  1.1231066  -1.3453379  -1.2987496   0.7521262   0.2987406  -0.13514175\n",
      " -1.0655993  -0.19663194 -0.76834434 -1.5129195   1.313538   -0.821364\n",
      " -0.6229849  -0.46779534  0.82151186 -0.28285417 -0.57393914  1.743551\n",
      " -0.6111156  -0.95072347  0.9262962   0.45251837  0.70872754  1.5180347\n",
      "  0.6519432   1.3305837   0.7525665   1.2801207   0.8188204  -0.47502205\n",
      "  0.6839735   0.87454796 -0.9637733  -1.7923251   0.6622329   0.04881697\n",
      "  1.046065   -0.83580637  0.55304813 -0.6927035  -0.332332   -0.40236983\n",
      " -0.3179529  -0.1042618   0.12807393  0.42631954 -0.5864083  -0.3658373\n",
      "  0.94953936  0.5347475   0.34912658 -1.5270344  -0.98640835  0.30433813\n",
      " -0.0803884  -1.0686924  -0.45101103 -0.01860649 -0.952559   -0.2536942\n",
      " -1.0479151   0.50564533 -0.22576164 -0.5595766   0.36027208 -0.751527\n",
      " -0.24069111 -0.7013722  -0.7379047  -0.78702754  0.5461682  -0.3149945\n",
      " -0.26477093  0.8797767   0.17341277 -0.47123808 -1.3698276  -0.33735433\n",
      " -0.4286512   0.9936398   0.21441725  0.35421774  0.5308947   0.2076749\n",
      "  0.9561441   0.06636083  1.1549746  -0.08596115 -0.45919818  0.65211934\n",
      " -0.7901923   0.70997965 -0.84516305 -0.7138937  -0.40814897 -0.6165425\n",
      "  1.0845927   0.8928486  -0.079838    0.4842487   1.1033062   0.11149327\n",
      "  1.4153805   0.9432786  -0.3905363   0.86147606  0.7655696  -1.0849291\n",
      " -0.65183663  0.4693192   0.32669795 -0.51203614  0.28878945  0.01063328\n",
      "  0.33405948  0.43044752 -0.18565156 -0.73701036 -0.98001     0.32752353\n",
      " -0.8817644  -0.5836564   0.11149327 -0.42149606  0.8581049  -0.9944579\n",
      " -0.05279981 -0.30797696  0.4301035   0.35291055 -0.05562059 -1.0292016\n",
      "  0.9253908   0.01441725 -0.43326077  0.03691467  0.6554905   0.4080189\n",
      "  0.84303784 -1.1931506  -0.3171273   1.1644001  -0.30715138  0.10874129\n",
      "  0.11747883 -0.24144791 -0.29683146  0.20093256 -0.25259343 -0.89297867\n",
      " -0.86814207 -0.23821433  0.25246334 -0.65073586], shape=(256,), dtype=float32), dense_shape=tf.Tensor([  2 128], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "for row in ds.take(3):\n",
    "    print('-----')\n",
    "    print(row)\n",
    "    print('mean_rgb:', row[0]['mean_rgb'])\n",
    "    print('mean_audio:', row[0]['mean_audio'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
